# To invoke, run:
#
# python compress_classifier.py -a resnet18 -p 10 -j 22 <path_to_imagenet_dataset> --pretrained --evaluate --quantize-eval --qe-config-file ../quantization/post_train_quant/resnet18_imagenet_post_train.yaml
# (Note that when '--qe-config-file' is passed, all other '--qe*' arguments are ignored. Only the settings in the YAML file are used)
#


quantizers:
  post_train_quantizer:
    class: PostTrainLinearQuantizer
    bits_activations: 6
    bits_parameters: 6
    bits_accum: 32

    # Quantization mode can be defined either with a single value for both weights and activations, or with
    # a nested dictionary specifying weights and activations separately.
    # All the results in the table above are using ASYMMETRIC for both weights and activations.
    mode: SYMMETRIC
    # Example of mixed definition:
    # mode:
    #   activations: ASYMMETRIC_UNSIGNED
    #   weights: SYMMETRIC

    # Path to stats file assuming this is being invoked from the 'classifier_compression' example directory
#    model_activation_stats: data/resnet18/resnet18_quant_stats.yaml
    # per_channel_wts: True code breaks.. Need to re-write.
    per_channel_wts: False
    clip_acts: AVG

    # Overrides section for run 6
#    overrides:
#    # First and last layers + element-wise add layers in 8-bits
#      conv1:
#        bits_weights: 8
#        bits_activations: 8
#      .*add:
#        bits_weights: 8
#        bits_activations: 8
#      fc:
#        bits_weights: 8
#        bits_activations: 8
#        clip_acts: NONE
