import datetime
from attrdict import AttrDict
import random
import numpy as np
import os, copy
import datetime
from pathlib import Path
import pandas as pd
import argparse


def collect_latency_summary(input_latency_dir_path):
    latency_stats = pd.DataFrame(columns=['name','edge_sec', 'tr_sec', 'cloud_sec', 'split_idx', 'total_sec'])
    for file in os.listdir(input_latency_dir_path):
        if file.endswith(".csv"):
            result_file_name = os.path.join(input_latency_dir_path, file)
            # df = pd.read_csv(input_latency_dir_path, index_col=0, header=None).T
            if ('True_True' in result_file_name) \
                    or ('True_False' in result_file_name) \
                    or ('False_True' in result_file_name) \
                    or ('False_False' in result_file_name):
                print(result_file_name)
                f = open(result_file_name, "r")
                lines = f.readlines()
                # print(lines[1])
                tmp_list =  lines[1].strip('\n').split(',')
                tmp_list = [round(float(x),6) for x in tmp_list]
                edge_sec = tmp_list[0]
                transmission_sec = tmp_list[1]
                cloud_sec = tmp_list[2]
                split_idx = int(tmp_list[3])
                total_sec = tmp_list[4]
                name = file.split('.csv')[0]
                latency_stats = latency_stats.append({ 'name': name,
                    'edge_sec': edge_sec, 'tr_sec': transmission_sec, 'cloud_sec': cloud_sec,
                    'split_idx': split_idx, 'total_sec': total_sec
                }, ignore_index=True)
                f.close()


    # print(latency_stats)
    latency_stats.to_csv(input_latency_dir_path + '/latency_summary.csv', index=False, header=True)
    return latency_stats



def change_names(orig_name):

    new_str={'_False_True': '_FT',
             '_True_False': '_TF',
             '_True_True': '_TT',
             '16_-1_16_False_False': 'CLOUD16',
             '_2_False_False': 'U2',
             '_4_False_False': 'U4',
             '_6_False_False': 'U6',
             '_8_False_False': 'U8',

             }
    for key, val in new_str.items():
        if key in orig_name:
            x = orig_name.split(key)[0]
            if val == 'U2' or val == 'U4' or val == 'U6' or val == 'U8' or val == 'CLOUD16':
                x = val
            else:
                x = x + val
            return x


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--net-df', '-n',default='resnet50_20200521-174448', type=lambda s: s.lower(),
                        help=' Needs timestamp folder generated by autosplit algorithm ')

    args = parser.parse_args()
    datadir = args.net_df


    input_mse_dir_path = 'generated/bit_search/' + datadir + '/'
    # input_latency_dir_path = 'generated/latency/' + datadir + '/'

    for bw in [1, 3, 10, 20]:
        input_latency_dir_path = 'generated/latency/{}/{}/'.format(datadir, bw)
        # logging.basicConfig(stream=sys.stderr, level=logging.INFO)
        # logger = logging.getLogger('LATENCY')
        latency_stats_df = collect_latency_summary(input_latency_dir_path)
        mse_stats_df = pd.read_csv(input_mse_dir_path + '/latency_mse_stats.csv')
        # print(mse_stats_df)

        # For each row in latency_df get
        for _, latency_row in latency_stats_df.iterrows():
            name, edge_sec, tr_sec, cloud_sec, split_idx, total_sec = latency_row
            idx = mse_stats_df[mse_stats_df['name'] == name].index

            if idx.empty:
                print('{} not found'.format(name))
                continue
            else:
                idx = idx[0]

            mse_stats_df.at[idx,'edge_sec'] = edge_sec
            mse_stats_df.at[idx,'tr_sec'] = tr_sec
            mse_stats_df.at[idx,'cloud_sec'] = cloud_sec
            mse_stats_df.at[idx,'latency'] = total_sec
        # end for stats
        mse_stats_df['name'] = mse_stats_df['name'].apply(change_names)
        mse_stats_df.to_csv(input_latency_dir_path + '/latency_mse_stats.csv',index=False, header=True)
        # end for bw

