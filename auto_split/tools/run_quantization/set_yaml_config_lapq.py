import numpy as np
import csv
from matplotlib import pyplot as plt
import yaml, os
from pathlib import Path
import io
import pandas as pd
from collections import OrderedDict
import shutil
import fileinput
import os
import argparse

# Used for hardware simulations
#Input: raw_data/resnet18.csv => adds bit_activation, bit_weights information => Output: bitwidth/resnet18_cloud.csv
def load_template_yaml(input_bits_folder, file_list, result_folder, quant_stats_file, FLOATBITS):

    cfg = OrderedDict()
    cfg['quantizers'] =  OrderedDict()
    cfg['quantizers']['post_train_quantizer']= OrderedDict()
    cfg['quantizers']['post_train_quantizer']['class'] = 'PostTrainLinearQuantizer'
    cfg['quantizers']['post_train_quantizer']['bits_activations'] = 'null'
    cfg['quantizers']['post_train_quantizer']['bits_parameters'] = 'null'
    cfg['quantizers']['post_train_quantizer']['bits_accum'] = 32
    cfg['quantizers']['post_train_quantizer']['mode'] = OrderedDict()
    cfg['quantizers']['post_train_quantizer']['mode']['activations'] = 'ASYMMETRIC_UNSIGNED'
    # cfg['quantizers']['post_train_quantizer']['mode']['activations'] = 'SYMMETRIC'
    cfg['quantizers']['post_train_quantizer']['mode']['weights'] = 'SYMMETRIC'

    cfg['quantizers']['post_train_quantizer']['model_activation_stats'] = quant_stats_file
    cfg['quantizers']['post_train_quantizer']['per_channel_wts'] = True
    cfg['quantizers']['post_train_quantizer']['inputs_quant_auto_fallback'] = True
    # cfg['quantizers']['post_train_quantizer']['clip_acts'] = 'AVG'



    basepath = Path(input_bits_folder)
    # files_in_basepath = basepath.iterdir()
    for filename in file_list:
        filepath = Path(input_bits_folder + '/' + filename + '.csv')
        cfg['quantizers']['post_train_quantizer']['overrides'] = OrderedDict()
        if not filepath.is_file():
            continue

        print(filepath.name)
        df = pd.read_csv(filepath)
        num_layers = len(df)
        print('num layers: {}'.format(num_layers))
        result_yaml_file = result_folder +  filename + '.yaml'
        for idx, row in df.iterrows():
            # print(row)
            layer_name, weight_bits, act_bits = row

            if weight_bits == FLOATBITS:
                continue
            # print(idx, layer_name)

            cfg['quantizers']['post_train_quantizer']['overrides'][layer_name] = OrderedDict()
            cfg['quantizers']['post_train_quantizer']['overrides'][layer_name]['bits_weights'] = weight_bits
            cfg['quantizers']['post_train_quantizer']['overrides'][layer_name]['bits_activations'] = act_bits

            # if layer_name == 'fc':
            #     cfg['quantizers']['post_train_quantizer']['overrides'][layer_name]['clip_acts'] = 'NONE'

        # print distiller pq.yaml file
        print(cfg)
        with io.open(result_yaml_file, 'w', encoding='utf8') as outfile:
            yaml.dump(cfg,outfile, default_flow_style=False, allow_unicode=True)

        # cp distiller script
        # shutil.copy(old_name, new_name)





def replace_special_characters(input_bits_folder):
    basepath = Path(input_bits_folder)
    files_in_basepath = basepath.iterdir()
    text_to_search="'null'"
    replacement_text='null'

    for filepath in files_in_basepath:

        if not filepath.is_file():
            continue

        filename=filepath.name
        if '.yaml' in filename:
            with fileinput.FileInput(filepath, inplace=True) as file:
                for line in file:
                    print(line.replace(text_to_search, replacement_text), end='')


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--net-df', '-n',default='resnet50_20200521-174448', type=lambda s: s.lower(),
                        help=' Needs timestamp folder generated by autosplit algorithm ')
    parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet50', type=lambda s: s.lower(),
                        help='add graph information to model stats dataframe')

    parser.add_argument('--bw', '-b', default='3', type=lambda s: s.lower(),
                        help='default bandwidth folder = 3 Mbps')

    args = parser.parse_args()
    input_bits_folder_name = args.net_df
    model_name = args.arch
    bw = args.bw

    root_dir = os.getcwd() + '/'
    input_file_list = os.path.join(root_dir,'generated','latency',input_bits_folder_name,bw,'latency_summary.csv')
    # input_file_list = root_dir + 'generated/latency/' + input_bits_folder_name  + '/latency_summary.csv'
    file_list_df = pd.read_csv(input_file_list)
    file_list = file_list_df['name'].tolist()
    input_bits_folder = root_dir + 'generated/bit_search/' + input_bits_folder_name + '/'
    result_folder = root_dir + 'generated/run_quantization/' + input_bits_folder_name + '/'

    Path(result_folder).mkdir(parents=True, exist_ok=True)

    # Set paths
    quant_stats_file = root_dir + 'data/'+ model_name + '/quant_stats_after_prepare_model.yaml'
    load_template_yaml(input_bits_folder, file_list, result_folder, quant_stats_file=quant_stats_file, FLOATBITS=16)
    replace_special_characters(result_folder)


