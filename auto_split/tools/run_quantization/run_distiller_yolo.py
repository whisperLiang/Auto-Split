import numpy as np
import csv
from matplotlib import pyplot as plt
import yaml, os
from pathlib import Path
import io
import pandas as pd
from collections import OrderedDict
import shutil, os, sys
import subprocess
import argparse
# def pushd(new_dir):
#     previous_dir = os.getcwd()
#     os.chdir(new_dir)
#     changed_dir = os.getcwd()
#     print('new dir: {} '.format(changed_dir))
#     return previous_dir
#
# def popd(previous_dir):
#     os.chdir(previous_dir)
#     changed_dir = os.getcwd()
#     print('new dir: {} '.format(changed_dir))
#     return

def subprocess_cmd(command, pushd_dir):
    process = subprocess.Popen(command,cwd=pushd_dir,stdout=subprocess.PIPE, shell=True)
    # process = subprocess.Popen(exec_str.split(),cwd=pushd_dir, stdout=subprocess.PIPE,shell=True)
    proc_out, proc_err = process.communicate()
    return proc_out, proc_err

def run_distiller(args):
    python_exec = args.pythonpath
    input_bits_folder_name = args.net_df
    device_id = args.deviceid
    model_name = args.arch
    # dataset=args.dataset
    cfgfile=args.cfg
    wgtsfile=args.weights
    imgsize = args.img_size
    batch_size = args.batch_size
    dataset_dir = args.data
    # Set paths
    root_dir = os.getcwd() + '/'
    input_bits_folder= root_dir + 'generated/run_quantization/'+ input_bits_folder_name + '/'
    basepath = Path(input_bits_folder)
    files_in_basepath = basepath.iterdir()

    with open('run_commands.sh', 'w') as f:
        for filepath in files_in_basepath:
            if not filepath.is_file():
                continue

            # if 'False' in filepath.name:
            #     continue

            if '.yaml' in filepath.name :
                distiller_path=root_dir+'../libs/distiller-master/'
                quant_script = root_dir + 'detection_models/yolov3_master/quantize_edge_dnn.py'
                pushd_dir=root_dir+'generated/quant_results/'+ input_bits_folder_name
                Path(pushd_dir).mkdir(parents=True, exist_ok=True)

                # Bash commands -- to run
                set_env1='export PYTHONPATH={}:{}'.format(distiller_path,os.getcwd())
                set_env2='export CUDA_VISIBLE_DEVICES={}'.format(device_id)
                # set_env2=''
                # More FLAGS:
                # --lapq-eval-memoize-dataloader
                # --lapq-eval-size 0.0028
                # --det
                # --lapq-init-mode LAPLACE
                # --lapq-init-method powell
                # cfgfile='detection_models/yolov3_master/cfg/yolov3-spp.cfg'
                # wgtsfile='<path to >/yolov3_data/yolov3-spp.pt'
                # filepath='data/yolov3-spp-416/yolov3-spp_post_train_test.yaml'
                exec_str='{} {} --device_yolo {} --img-size {} --data {} --cfg {}  --weights {} ' \
                         ' -p 10 -j 4 --eval ' \
                         '--quant-method {} --quantize-eval --qe-lapq  ' \
                         '--lapq-maxiter 2 --qe-config-file {} -b {} ' \
                         '  --lapq-search-clipping\n'.format(python_exec, quant_script, device_id,
                                                           imgsize,dataset_dir, cfgfile,wgtsfile,
                                                           'fake_pq',filepath, batch_size)


                print(set_env1)
                print(set_env2)
                print(exec_str)

                bash_cmd = set_env1 + ';' + set_env2 + ';' + exec_str
                f.write(bash_cmd)
                proc_out, proc_error = subprocess_cmd(bash_cmd, pushd_dir)
                # print(proc_error)



if __name__ == '__main__':


    parser = argparse.ArgumentParser(prog='run_distiller_yolo.py')
    parser.add_argument('-b', '--batch-size', default=16, type=int)

    # default = '~/edge-cloud-collaboration/auto_split/detection_models/yolov3_master/cfg/yolov3-tiny.cfg',
    parser.add_argument('--cfg', type=str, help='*.cfg path')
    parser.add_argument('--data', type=str, default='~/edge-cloud-collaboration/auto_split/detection_models/yolov3_master/data/coco2017.data',
                        help='*.data path')

    # default = '<path to >/yolov3_data/yolov3-tiny.pt'
    parser.add_argument('--weights', type=str, help='weights path')
    # parser.add_argument('--batch-size', type=int, default=16, help='size of each image batch')

    # default = 512,
    parser.add_argument('--img-size', type=int, help='inference size (pixels): From source 320,416,512,608')

    # default = 'resnet50_20200521-174448',
    parser.add_argument('--net-df', '-n',type=lambda s: s.lower(),
                        help=' Needs timestamp folder generated by autosplit algorithm ')
    # default='resnet50',
    parser.add_argument('--arch', '-a', metavar='ARCH', type=lambda s: s.lower(),
                        help='add graph information to model stats dataframe')

    parser.add_argument('--deviceid', type=int, help='cuda_device_id: 0,1,2,3..')
    # parser.add_argument('dataset', metavar='DATASET_DIR',
    #                     default='~/datasets/ImageNet2017/ILSVRC/Data/CLS-LOC/',
    #                     help='path to dataset')
    parser.add_argument('--pythonpath', type=str, default='~/anaconda3/envs/pyt_13/bin/python' ,
                        help='full path to python executable')
    # python_exec='python'
    args = parser.parse_args()

    run_distiller(args)

